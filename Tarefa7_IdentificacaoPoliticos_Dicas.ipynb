{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ChPfykV8okAt",
        "ik8hBBUIrUCa",
        "m42sFerfJND1",
        "hnavM10uJDPQ",
        "GbQBsgCz1W4K"
      ],
      "authorship_tag": "ABX9TyNywiyfuIaZKZ4PChVxts0h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/idl/blob/main/Tarefa7_IdentificacaoPoliticos_Dicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChPfykV8okAt"
      },
      "source": [
        "# Tarefa 7 - Identificação facial \n",
        "\n",
        "Uma agremiação brasileira optou por usar um método de identificação facial para autenticar o cadastro de seus filiados. Infelizmente, a solução foi pouco testada e foi um gargalo no processamento dos cadastros. \n",
        "\n",
        "Nessa tarefa, vamos testar os métodos de reconhecimento facial com políticos historicamente vinculados à referida agremiação (alguns não estão mais filiados à mesma). \n",
        "\n",
        "Para completar a tarefa, vamos também testar a rede treinada com fotos dos mesmos políticos com máscaras faciais e avaliar acurácia nas predições com as redes originalmente treinadas. \n",
        "\n",
        "O dataset foi disponibilizado no github com os conjuntos de treinamento e validação separados. Um segundo conjunto de validação, com máscaras também está disponível no repositório. \n",
        "\n",
        "Abaixo, a seqüência para fazer download do dataset e a extração das faces. \n",
        "\n",
        "Você deverá: \n",
        "\n",
        "1. Escolher um método para implementar a identificação (embedding+SVM ou transfer learning com fine tuning, conforme as lições anteriores) \n",
        "\n",
        "2. Treinar a rede, avaliar acurácia de treinamento e validação\n",
        "\n",
        "3. Avaliar a acurácia para o conjunto das imagens com máscara facial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik8hBBUIrUCa"
      },
      "source": [
        "## Alguns ajustes iniciais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vKizuGIeig7"
      },
      "source": [
        "!pip install mtcnn\n",
        "!pip install git+https://github.com/jsansao/keras-vggface.git\n",
        "!pip install keras_applications\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evKOfp4UtJ7m"
      },
      "source": [
        "!wget https://github.com/jsansao/TucanoDataset/archive/refs/heads/main.zip\n",
        "!unzip main.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42sFerfJND1"
      },
      "source": [
        "## Funções para extração das faces e geração do dataset com faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNsoM-YNeIuP"
      },
      "source": [
        "# face detection \n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "import mtcnn\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = mtcnn.MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# enumerate files\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + filename\n",
        "\t\t# get face\n",
        "\t\tface = extract_face(path, (224,224))\n",
        "\t\t# store\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces\n",
        "\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# enumerate folders, on per class\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# skip any files that might be in the dir\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# load all faces in the subdirectory\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# create labels\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\t# store\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnavM10uJDPQ"
      },
      "source": [
        "## Geração dos arquivos com as faces e rótulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYpCWAmhePGI"
      },
      "source": [
        "# load train dataset\n",
        "trainX, trainy = load_dataset('/content/TucanoDataset-main/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "testX, testy = load_dataset('/content/TucanoDataset-main/val/')\n",
        "# load mask dataset\n",
        "valX, valy = load_dataset('/content/TucanoDataset-main/masc_val/')\n",
        "\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('tucano-faces-dataset.npz', trainX, trainy, testX, testy, valX, valy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicie seu código aqui"
      ],
      "metadata": {
        "id": "GbQBsgCz1W4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# código "
      ],
      "metadata": {
        "id": "dKRhVSkX1VaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "import mtcnn\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions\n"
      ],
      "metadata": {
        "id": "uVJpIsKSOxdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
      ],
      "metadata": {
        "id": "doktTiYtOyif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(model, face_pixels):\n",
        "\t# scale pixel values\n",
        "  samples = face_pixels.astype('float32')\n",
        "  samples = expand_dims(samples, axis=0)\n",
        "  samples = preprocess_input(samples, version=2)\n",
        "  # transform face into one sample\n",
        "  # make prediction to get embedding\n",
        "  yhat = model.predict(samples)\n",
        "  return yhat[0]\n",
        "     "
      ],
      "metadata": {
        "id": "wC65JHoxO2Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert each face in the train set to an embedding\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "\n",
        "# convert each face in the test set to an embedding\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "\n",
        "# convert each face in the val set to an embedding\n",
        "newValX = list()\n",
        "for face_pixels in valX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewValX.append(embedding)\n",
        "newValX = asarray(newValX)\n",
        "print(newValX.shape)"
      ],
      "metadata": {
        "id": "5FfBUqRUO5qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savez_compressed('tucano-faces-embeddings.npz', newTrainX, trainy, newTestX, testy, newValX, valy)"
      ],
      "metadata": {
        "id": "hyq4A2CoPH3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# develop a classifier for the tucano\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "# load dataset\n",
        "data = load('tucano-faces-embeddings.npz')\n",
        "trainX, trainy, testX, testy, valX, valy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\n",
        "print('Dataset: train=%d, test=%d, val=%d' % (trainX.shape[0], testX.shape[0], valX.shape[0]))\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "valX = in_encoder.transform(valX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "valy = out_encoder.transform(valy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# predict\n",
        "yhat_train = model.predict(trainX)\n",
        "yhat_test = model.predict(testX)\n",
        "yhat_val = model.predict(valX)\n",
        "# score\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "score_val = accuracy_score(valy, yhat_val)\n",
        "# summarize\n",
        "print('Accuracy: train=%.3f, test=%.3f, val=%.3f' % (score_train*100, score_test*100, score_val*100))\n",
        "     "
      ],
      "metadata": {
        "id": "KnMXtCYlQ42e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}